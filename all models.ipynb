{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate"
      ],
      "metadata": {
        "id": "Nnmde2F0_1yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rCowjDuj9GZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SQuAD dataset (use only certain % if gpu access is low)\n",
        "dataset = load_dataset(\"squad\", split=\"train[:100%]\")"
      ],
      "metadata": {
        "id": "w06AOwFNB9su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models and tokenizers\n",
        "model_names = [\n",
        "    \"distilbert-base-uncased-distilled-squad\",\n",
        "    \"bert-base-uncased\",\n",
        "    \"albert/albert-base-v1\",\n",
        "    \"huawei-noah/TinyBERT_General_4L_312D\",\n",
        "    \"microsoft/MiniLM-L12-H384-uncased\"\n",
        "]"
      ],
      "metadata": {
        "id": "VEb8P2LMB_1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {model_name: AutoModelForQuestionAnswering.from_pretrained(model_name) for model_name in model_names}\n",
        "tokenizers = {model_name: AutoTokenizer.from_pretrained(model_name) for model_name in model_names}\n"
      ],
      "metadata": {
        "id": "qpnfoOENCBhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples, tokenizer):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(questions, examples[\"context\"], max_length=384, truncation=\"only_second\", return_offsets_mapping=True, padding=\"max_length\")\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions, end_positions = [], []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        idx = next((idx for idx, seq in enumerate(sequence_ids) if seq == 1), None)\n",
        "        if idx is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "            continue\n",
        "\n",
        "        context_start = idx\n",
        "        context_end = next((idx for idx, seq in enumerate(sequence_ids[idx:], start=idx) if seq != 1), len(sequence_ids)) - 1\n",
        "\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            try:\n",
        "                start_idx = next(idx for idx in range(context_start, context_end + 1) if offset[idx][0] <= start_char and offset[idx][1] > start_char) - 1\n",
        "\n",
        "            except StopIteration:\n",
        "                start_idx = 0\n",
        "            try:\n",
        "                end_idx = next(idx for idx in range(context_end, context_start - 1, -1) if offset[idx][1] >= end_char)\n",
        "            except StopIteration:\n",
        "                end_idx = 0\n",
        "\n",
        "\n",
        "            start_positions.append(start_idx)\n",
        "            end_positions.append(end_idx)\n",
        "\n",
        "    inputs[\"start_positions\"], inputs[\"end_positions\"] = start_positions, end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "F3VgijOEFNHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_squad = [dataset.map(lambda x: preprocess_function(x, tokenizers[model_name]), batched=True, remove_columns=dataset.column_names)\n",
        "                   for model_name in model_names]"
      ],
      "metadata": {
        "id": "Pwb_OfvfABS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"squad\")"
      ],
      "metadata": {
        "id": "mWIiP46eADmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "    start_positions, end_positions = labels\n",
        "\n",
        "    predicted_starts = np.argmax(start_logits, axis=1)\n",
        "    predicted_ends = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    return {\"start_accuracy\": np.mean(predicted_starts == start_positions),\n",
        "            \"end_accuracy\": np.mean(predicted_ends == end_positions)}"
      ],
      "metadata": {
        "id": "aZtrU-M1AF_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(model_names):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_model_{i+1}\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        push_to_hub=False\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=models[model],\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_squad[i],\n",
        "        eval_dataset=tokenized_squad[i],\n",
        "        tokenizer=tokenizers[model],\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.evaluate()"
      ],
      "metadata": {
        "id": "nVDR70ydcQAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}